# 概要
## 何したの？
画像分類において、学習データに含まれる各クラスのサンプル数を人工的に不均衡にすることで、同一の評価データ(均衡)に対する分類精度が上がるかを検証した。<br>
不均衡な構成はクラス間の類似度に基づくものであり、判別難易度の高いクラスの割合を大きくする一方で判別が容易であるクラスの割合を小さくしたものである。

## 直感的な例
入力画像を「犬」「猫」「車」のいずれかに分類するモデルを構築する例を考える。すると車は動物でないことから、「車 or 車ではない」という判別が
できるようになるのは容易であると自然に考えられる。一方で「犬か猫か」の判別が難しくなると考えられるため、学習データセットの各クラスの構成を
均衡にするのではなく、「車」の画像を減らしその分「犬」and「猫」の割合を大きくすると学習効率が向上すると考えられる。<br>

上記の例において「動物かそうでないか」という判断要素はクラス間の類似度と言えるが、人間の感覚によるものである。
実際には定量的に算出する必要があるため、ここではクラス間類似度を次元空間における重複度から近似的に計算を行う。<br>
(参考: [Cummulative Spectral Gradient](https://arxiv.org/abs/1905.07299))

# 何のために？
データ収集の効率性を向上するため。

# 方法
1. クラス間の類似度を小規模のデータセット(各クラスサンプル数500枚くらい)から計算し、類似度行列を作成する。
2. 以下の3種類の構成のそれぞれで同規模の学習データを構成し、学習したモデルで同一の均衡な評価データに対する分類精度を比較する。
  * 均衡 (balanced) : 各クラスのサンプル数が等しい均衡なデータ。
  * 複雑度高 (complexed) : 判別難易度が高いクラスを大きくしたデータ。
  * 複雑度低 (simple) : 判別難易度が低いクラスを大きくしたデータ。

# 結果
学習データのサイズ(=学習に用いる画像の枚数)が小さい場合、複雑度を上げると分類精度はかなり悪化した。<br>
しかし学習データのサイズの増加と共に分類精度は上昇する傾向がどの実験においても見られ、均衡データでの学習時よりも改善されたケースもあった。


# 考察
判別が容易なクラスが判別可能になった上で、判別が難しいクラスを学習すると上手くいくのではないか？
  * 問題集で例えるなら、基本問題をしっかり押さえた上で応用問題で練習すると学習がうまく進む。
  * 初めから応用問題ばかり解こうとしないのが重要 (データサイズが小さい場合に複雑度を上げるとモデルが悪化したのはこれが原因と考えられる)。

# 課題・今後の可能性
* 提案手法が効果を発揮するのに必要なデータ数が分からない。
* そもそも汎用的にいろんなデータに通用するものかも検証できていない。
* 上手くいけば自然言語処理にも活かせる(はず)
